# -*- coding: utf-8 -*-
"""Loan_Approval.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NovK3D7K69pDhwyjw60YBvdwPVegk0qv

**Problem Statement:** Here are some attributes in this dataset, so that we can predict that whether or not person is elligible for the loan.

**Link to the dataset:** https://www.kaggle.com/granjithkumar/loan-approval-data-set

**Datset Description:** This datset consists of 12 columns about the applicant eligibility for the loan. 

Columns of dataset are:

*   **Loan_ID:** Loan ID of an applicant. Loan ID is unique for each applicant.
*   **Gender:** Gender of an applicant.
*   **Married:** Maritial status of an applicant.
*   **Dependents:** It shows how many family members are dependent on the applicant?
*   **Education:** About Education status of an applicant.
*   **Self_Employed:** Whether the applicant is self employed or not?
*   **ApplicantIncome:** Monthly income of the applicant.
*   **CoapplicantIncome:** Side income of an applicant.
*   **LoanAmount:** Amount on which applicant applied.
*   **Loan_Amount_Term:** Term of loan in months.
*   **Credit_History:** Credit history meets guidelines for that loan.
*   **Property_Area:** Residential area of an applicant (Urban/ Semi Urban/ Rural)
*   **Loan_Status:** Loan approved Status (Yes/No)

#Importing necessary libraries
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np # for scientific calculations
import pandas as pd # for data manipulation and analysis
import matplotlib.pyplot as plt # for visualization
import seaborn as sb # for visualization
from sklearn.preprocessing import LabelEncoder # to convert categorical data into numeric data
from sklearn.model_selection import train_test_split # to divide data into training and testing purpose
from sklearn.linear_model import LogisticRegression # to call logistic regression algorithm
from sklearn.tree import DecisionTreeClassifier # to call decision tree algorithm
from sklearn.svm import SVC # to call support vector machine (classification) algorithm
from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB # to call naive bayse (multinominal and gaussian) algorithm
from sklearn.metrics import confusion_matrix, accuracy_score # to calculate confusion matrix, accuracy score 
import pickle # to save the trained model

"""# Load the datset"""

loan_data = pd.read_csv("/content/drive/MyDrive/Loan Approval System/Loan_Train.csv") #read csv files using pandas
loan_data.head() #first 5 rows of dataset

"""# Basic Information"""

print("Shape of dataset: ",loan_data.shape) # print the shape of data

print("Columns are present in datset: \n",loan_data.columns) # print the columns which are present in the dataet

loan_data.info()

loan_data.describe()

loan_data.corr()

"""# EDA (Exploratory Data Analysis) and Data Visulalization

## Remove unnecessory column/s
"""

loan_data = loan_data.drop(["Loan_ID"], axis = 1)
loan_data.head()

"""## Null values counting"""

loan_data.isnull().sum() # Check how many null values are present in particular column

#Replace all the null values with respective vaules of that column

loan_data["Gender"] = loan_data["Gender"].replace(np.NaN, "Female") # Female replaced NaN
loan_data["Married"] = loan_data["Married"].replace(np.NaN, "No") # No replaced NaN
loan_data["Dependents"] = loan_data["Dependents"].replace(["0", "1", "2", "3+", np.NaN], [0, 1, 2, 3, 0]) # '0', '1', '2', '3+', NaN replaced by 0, 1, 2, 3, 0
loan_data["Self_Employed"] = loan_data["Self_Employed"].replace(np.NaN, "Yes") # Yes replaced NaN
loan_data["LoanAmount"] = loan_data["LoanAmount"].fillna(method = "ffill") # Fill null values using forward fill method
loan_data["LoanAmount"] = loan_data["LoanAmount"].replace(np.NaN, 128) 
loan_data["Loan_Amount_Term"] = loan_data["Loan_Amount_Term"].fillna(method = "ffill") # Fill null values using forward fill method
loan_data["Credit_History"] = loan_data["Credit_History"].replace(np.NaN, 0) # 0 replaced NaN

loan_data.isnull().sum()

gender_dummies = pd.get_dummies(loan_data.Gender, drop_first = True) 
married_dummies = pd.get_dummies(loan_data.Married, drop_first = True)
dependents_dummies = pd.get_dummies(loan_data.Dependents, drop_first = True)
education_dummies = pd.get_dummies(loan_data.Education, drop_first = True)
employment_dummies = pd.get_dummies(loan_data.Self_Employed, drop_first = True)
term_dummies = pd.get_dummies(loan_data.Loan_Amount_Term, drop_first = True)
credit_hstory_dummies = pd.get_dummies(loan_data.Credit_History, drop_first = True)
area_dummies = pd.get_dummies(loan_data.Property_Area, drop_first = True)

# print(gender_dummies.nunique())
# print(married_dummies.nunique())
# print(dependents_dummies.nunique())
# print(education_dummies.nunique())
# print(employment_dummies.nunique())
# print(term_dummies.nunique())
# print(credit_hstory_dummies.nunique())
# print(area_dummies.nunique())

"""## One Hot Encoding"""

loan_data = pd.concat([loan_data, gender_dummies, married_dummies, dependents_dummies, education_dummies, employment_dummies, term_dummies, credit_hstory_dummies, area_dummies], axis = "columns")

loan_data.head()

"""## Convert Categorical data into Numerical data"""

le = LabelEncoder()

loan_data["Gender"] = le.fit_transform(loan_data["Gender"]) # 1 = Male, 0 = Female
loan_data["Married"] = le.fit_transform(loan_data["Married"]) # 0 = No(Unmarried), 1 = Yes(Married)
loan_data["Education"] = le.fit_transform(loan_data["Education"]) # 0 = Graduate, 1 = Not Graduate
loan_data["Self_Employed"] = le.fit_transform(loan_data["Self_Employed"]) # 0 = No, 1 = Yes
loan_data["Property_Area"] = le.fit_transform(loan_data["Property_Area"]) # 2 = Urban, 0 = Rural, 1 = Semiurban
loan_data["Loan_Status"] = le.fit_transform(loan_data["Loan_Status"]) # 1 = Y(Yes), 0 = N(No)

loan_data.head()

"""## Data Visualization"""

loan_data.corr()

plt.figure(figsize = (10,10))
plt.title("Correlation of columns to each other")
sb.heatmap(loan_data.corr(), annot = True);

plt.title("Countplot of Gender")
sb.countplot(x = "Gender", data = loan_data); # 1 = Male, 0 = Female

plt.title("Education")
sb.countplot(x = "Education", data = loan_data); # 0 = Graduate, 1 = Non-graduate/Under graduate

plt.title("Marraige Ratio")
sb.countplot(x = "Married", data = loan_data); # 0 = No(Unmarried), 1 = Yes(Married)

plt.title("Dependents according to Employment")
sb.countplot(x = "Self_Employed", hue = "Dependents", data = loan_data); # 0 = No, 1 = Yes

values = loan_data["Credit_History"].value_counts() # extract the values
x = values.values # values(left) is variable, values(right) is property
labels = values.index
plt.title("Credit History")
plt.pie(x = x, labels = labels, data = loan_data, counterclock = False, startangle = 90);

p_area = loan_data["Property_Area"].value_counts()
values = p_area.values
labels = p_area.index
plt.title("Property Area")
plt.pie(x = values, labels = labels, data = loan_data, counterclock = False, startangle = 90, wedgeprops = {"width": 0.5}); # 2 = Urban, 0 = Rural, 1 = Semiurban

plt.title("Loan Status")
sb.countplot(x = "Loan_Status", data = loan_data); # 1 = Y(Yes), 0 = N(No)

loan_data = loan_data.drop(columns = ["Gender", "Married", "Dependents", "Education",	"Self_Employed", "Loan_Amount_Term",	"Credit_History",	"Property_Area"], axis = 1)
loan_data.head()

"""## Extrcat features and target"""

features = loan_data.drop(columns = ["Loan_Status"], axis = 1)
print("Features:\n", features.head())

target = loan_data["Loan_Status"]
print("Target:\n", target)

"""## Divide data into training and testing"""

xtrain, xtest, ytrain, ytest = train_test_split(features, target, test_size = 0.3, random_state = 0)

print("Shape of X-train:", xtrain.shape)
print("Shape of X-test:", xtest.shape)
print("Shape of Y-train:", ytrain.shape)
print("Shape of Y-test:", ytest.shape)

"""## Model Creation, Training and Testing

### Logistic Regression
"""

lr_model = LogisticRegression()
lr_model.fit(xtrain, ytrain) # from xtrain it starts learning from features, from ytrain it learns the output.

"""### Prediction"""

lr_prediction = lr_model.predict(xtest)
print("Prediction given by model:\n", lr_prediction)

"""### Confusion Matrix and Accuracy Score"""

matrix = confusion_matrix(ytest, lr_prediction)
print("Confusion Matrix of model:\n", matrix)

accuracy = accuracy_score(ytest, lr_prediction)
print("Accuracy of model: {}%".format(round(accuracy,4)*100))

"""### Decision Tree"""

d_tree = DecisionTreeClassifier()
d_tree.fit(xtrain, ytrain)

"""### Prediction"""

d_tree_pred = d_tree.predict(xtest)
print("Predictions given by model:\n", d_tree_pred)

"""### Confusion Matrix and Accuracy"""

d_tree_matrix = confusion_matrix(ytest, d_tree_pred)
print("Confusion Matrix of model:\n", d_tree_matrix)

d_tree_accuracy = accuracy_score(ytest, d_tree_pred)
print("Accuracy of model: {}%".format(round(d_tree_accuracy, 4)*100))

"""### Support Vector Machine"""

svm_c = SVC()
svm_c.fit(xtrain, ytrain)

"""### Prediction"""

svm_pred = svm_c.predict(xtest)
print("Predictions given by model:\n", svm_pred)

"""### Confusion Matrix and Accuracy"""

svm_matrix = confusion_matrix(ytest, svm_pred)
print("Confusion Matrix of model:\n", svm_matrix)

svm_accuracy = accuracy_score(ytest, svm_pred)
print("Accuracy of model: {}%".format(round(svm_accuracy, 4)*100))

"""### Naive Bayes

1. Gaussian
2. Multinomial
3. Bernaolli

### 1. Gaussian Naive Bayes
"""

gnb = GaussianNB()
gnb.fit(xtrain, ytrain)

gnb_pred = gnb.predict(xtest)
print("Predictions given by model:\n", gnb_pred)

"""### Confusion Matrix and Accuarcy Score"""

gnb_matrix = confusion_matrix(ytest, gnb_pred)
print("Confusion Matrix of a model:\n", gnb_matrix)

gnb_accuracy = accuracy_score(ytest, gnb_pred)
print("Accuracy of model: {}%".format(round(gnb_accuracy, 4)*100))

"""### 2. Multinomial Naive Bayse"""

mnb = MultinomialNB()
mnb.fit(xtrain, ytrain)

"""### Prediction"""

mnb_pred = mnb.predict(xtest)
print("Prediction given by model:\n", mnb_pred)

"""### Confusion Matrix and Accuracy Score"""

mnb_matrix = confusion_matrix(ytest, mnb_pred)
print("Confusion Matrix of model:\n", mnb_matrix)

mnb_accuracy = accuracy_score(ytest, mnb_pred)
print("Accuracy of model: {}%".format(round(mnb_accuracy, 4)*100))

"""### 3. Bernoulli Naive Bayes"""

bnb = BernoulliNB()
bnb.fit(xtrain, ytrain)

"""### Prediction"""

bnb_pred = bnb.predict(xtest)
print("Prediction given by the model:\n", bnb_pred)

"""### Confusion Matrix and Accuracy Score"""

bnb_matrix = confusion_matrix(ytest, bnb_pred)
print("Confusion Matrix of a model:\n", bnb_matrix)

bnb_accuracy = accuracy_score(ytest, bnb_pred)
print("Accuracy of a model: {}%".format(round(bnb_accuracy, 4)*100))

"""## Save the model """

file = open("loan_approval_model.pkl", "wb")
pickle.dump(lr_model, file)